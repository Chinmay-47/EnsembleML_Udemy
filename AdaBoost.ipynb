{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AdaBoost.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO+K6u3CGjnUNpkQ//9F+qo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chinmay-47/EnsembleML_Udemy/blob/master/AdaBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4BNrjBUVsPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division\n",
        "from builtins import range, input\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from Random_Forest_Classifier_Udemy import get_data\n",
        "\n",
        "\n",
        "class AdaBoost:\n",
        "  def __init__(self, M):\n",
        "    self.M = M\n",
        "\n",
        "  def fit(self, X, Y):\n",
        "    self.models = []\n",
        "    self.alphas = []\n",
        "\n",
        "    N, _ = X.shape\n",
        "    W = np.ones(N) / N\n",
        "\n",
        "    for m in range(self.M):\n",
        "      tree = DecisionTreeClassifier(max_depth=1)\n",
        "      tree.fit(X, Y, sample_weight=W)\n",
        "      P = tree.predict(X)\n",
        "\n",
        "      err = W.dot(P != Y)\n",
        "      alpha = 0.5*(np.log(1 - err) - np.log(err))\n",
        "\n",
        "      W = W*np.exp(-alpha*Y*P) # vectorized form\n",
        "      W = W / W.sum() # normalize so it sums to 1\n",
        "\n",
        "      self.models.append(tree)\n",
        "      self.alphas.append(alpha)\n",
        "\n",
        "  def predict(self, X):\n",
        "    # NOT like SKLearn API\n",
        "    # we want accuracy and exponential loss for plotting purposes\n",
        "    N, _ = X.shape\n",
        "    FX = np.zeros(N)\n",
        "    for alpha, tree in zip(self.alphas, self.models):\n",
        "      FX += alpha*tree.predict(X)\n",
        "    return np.sign(FX), FX\n",
        "\n",
        "  def score(self, X, Y):\n",
        "    # NOT like SKLearn API\n",
        "    # we want accuracy and exponential loss for plotting purposes\n",
        "    P, FX = self.predict(X)\n",
        "    L = np.exp(-Y*FX).mean()\n",
        "    return np.mean(P == Y), L\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    \n",
        "  X, Y = get_data()\n",
        "  Y[Y == 0] = -1 # make the targets -1,+1\n",
        "  Ntrain = int(0.8*len(X))\n",
        "  Xtrain, Ytrain = X[:Ntrain], Y[:Ntrain]\n",
        "  Xtest, Ytest = X[Ntrain:], Y[Ntrain:]\n",
        "\n",
        "  T = 200\n",
        "  train_errors = np.empty(T)\n",
        "  test_losses = np.empty(T)\n",
        "  test_errors = np.empty(T)\n",
        "  for num_trees in range(T):\n",
        "    if num_trees == 0:\n",
        "      train_errors[num_trees] = None\n",
        "      test_errors[num_trees] = None\n",
        "      test_losses[num_trees] = None\n",
        "      continue\n",
        "    if num_trees % 20 == 0:\n",
        "      print(num_trees)\n",
        "\n",
        "    model = AdaBoost(num_trees)\n",
        "    model.fit(Xtrain, Ytrain)\n",
        "    acc, loss = model.score(Xtest, Ytest)\n",
        "    acc_train, _ = model.score(Xtrain, Ytrain)\n",
        "    train_errors[num_trees] = 1 - acc_train\n",
        "    test_errors[num_trees] = 1 - acc\n",
        "    test_losses[num_trees] = loss\n",
        "\n",
        "    if num_trees == T - 1:\n",
        "      print(\"final train error:\", 1 - acc_train)\n",
        "      print(\"final test error:\", 1 - acc)\n",
        "\n",
        "  plt.plot(test_errors, label='test errors')\n",
        "  plt.plot(test_losses, label='test losses')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(train_errors, label='train errors')\n",
        "  plt.plot(test_errors, label='test errors')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}