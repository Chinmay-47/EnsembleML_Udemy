{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Random_Forest_Classifier_Udemy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPLHrVpBcW7w0FbsdfRmyPT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chinmay-47/EnsembleML_Udemy/blob/master/Random_Forest_Classifier_Udemy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTCthL9M-0zT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "3fbc354f-1913-4d93-a161-b5623ed61872"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "from future.utils import iteritems\n",
        "from builtins import range, input\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "NUMERICAL_COLS = ()\n",
        "CATEGORICAL_COLS = np.arange(22) + 1 # 1..22 inclusive\n",
        "\n",
        "# transforms data from dataframe to numerical matrix\n",
        "# one-hot encodes categories and normalizes numerical columns\n",
        "# we want to use the scales found in training when transforming the test set\n",
        "# so only call fit() once\n",
        "# call transform() for any subsequent data\n",
        "class DataTransformer:\n",
        "  def fit(self, df):\n",
        "    self.labelEncoders = {}\n",
        "    self.scalers = {}\n",
        "    for col in NUMERICAL_COLS:\n",
        "      scaler = StandardScaler()\n",
        "      scaler.fit(df[col].reshape(-1, 1))\n",
        "      self.scalers[col] = scaler\n",
        "\n",
        "    for col in CATEGORICAL_COLS:\n",
        "      encoder = LabelEncoder()\n",
        "      # in case the train set does not have 'missing' value but test set does\n",
        "      values = df[col].tolist()\n",
        "      values.append('missing')\n",
        "      encoder.fit(values)\n",
        "      self.labelEncoders[col] = encoder\n",
        "\n",
        "    # find dimensionality\n",
        "    self.D = len(NUMERICAL_COLS)\n",
        "    for col, encoder in iteritems(self.labelEncoders):\n",
        "      self.D += len(encoder.classes_)\n",
        "    print(\"dimensionality:\", self.D)\n",
        "\n",
        "  def transform(self, df):\n",
        "    N, _ = df.shape\n",
        "    X = np.zeros((N, self.D))\n",
        "    i = 0\n",
        "    for col, scaler in iteritems(self.scalers):\n",
        "      X[:,i] = scaler.transform(df[col].values.reshape(-1, 1)).flatten()\n",
        "      i += 1\n",
        "\n",
        "    for col, encoder in iteritems(self.labelEncoders):\n",
        "      # print \"transforming col:\", col\n",
        "      K = len(encoder.classes_)\n",
        "      X[np.arange(N), encoder.transform(df[col]) + i] = 1\n",
        "      i += K\n",
        "    return X\n",
        "\n",
        "  def fit_transform(self, df):\n",
        "    self.fit(df)\n",
        "    return self.transform(df)\n",
        "\n",
        "\n",
        "def replace_missing(df):\n",
        "  # standard method of replacement for numerical columns is median\n",
        "  for col in NUMERICAL_COLS:\n",
        "    if np.any(df[col].isnull()):\n",
        "      med = np.median(df[ col ][ df[col].notnull() ])\n",
        "      df.loc[ df[col].isnull(), col ] = med\n",
        "\n",
        "  # set a special value = 'missing'\n",
        "  for col in CATEGORICAL_COLS:\n",
        "    if np.any(df[col].isnull()):\n",
        "      print(col)\n",
        "      df.loc[ df[col].isnull(), col ] = 'missing'\n",
        "\n",
        "\n",
        "def get_data():\n",
        "  df = pd.read_csv('mushroom.data', header=None)\n",
        "\n",
        "  # replace label column: e/p --> 0/1\n",
        "  # e = edible = 0, p = poisonous = 1\n",
        "  df[0] = df.apply(lambda row: 0 if row[0] == 'e' else 1, axis=1)\n",
        "\n",
        "  # check if there is missing data\n",
        "  replace_missing(df)\n",
        "\n",
        "  # transform the data\n",
        "  transformer = DataTransformer()\n",
        "\n",
        "  X = transformer.fit_transform(df)\n",
        "  Y = df[0].values\n",
        "  return X, Y\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  X, Y = get_data()\n",
        "\n",
        "  # do a quick baseline test\n",
        "  baseline = LogisticRegression()\n",
        "  print(\"CV baseline:\", cross_val_score(baseline, X, Y, cv=8).mean())\n",
        "\n",
        "  # single tree\n",
        "  tree = DecisionTreeClassifier()\n",
        "  print(\"CV one tree:\", cross_val_score(tree, X, Y, cv=8).mean())\n",
        "\n",
        "  model = RandomForestClassifier(n_estimators=20) # try 10, 20, 50, 100, 200\n",
        "  print(\"CV forest:\", cross_val_score(model, X, Y, cv=8).mean())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dimensionality: 139\n",
            "CV baseline: 0.9260029188161825\n",
            "CV one tree: 0.94264211046895\n",
            "CV forest: 0.9400556611458051\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}